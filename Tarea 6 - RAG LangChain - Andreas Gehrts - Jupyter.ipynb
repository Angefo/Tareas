{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "656a8df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cargar librer√≠as necesarias\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a88a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza de texto\n",
    "file_path = r\"D:\\Documentos\\Libros\\The Project Gutenberg eBook of The Strange Case of Dr. Jekyll and Mr. Hyde.txt\"\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2bdbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo contenido\n",
    "start = raw_text.find(\"STORY OF THE DOOR\")\n",
    "end = raw_text.find(\"*** END OF THE PROJECT GUTENBERG EBOOK\")\n",
    "clean_text = raw_text[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc214f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1254, which is longer than the specified 500\n",
      "Created a chunk of size 1128, which is longer than the specified 500\n",
      "Created a chunk of size 802, which is longer than the specified 500\n",
      "Created a chunk of size 767, which is longer than the specified 500\n",
      "Created a chunk of size 4319, which is longer than the specified 500\n",
      "Created a chunk of size 598, which is longer than the specified 500\n",
      "Created a chunk of size 530, which is longer than the specified 500\n",
      "Created a chunk of size 566, which is longer than the specified 500\n",
      "Created a chunk of size 512, which is longer than the specified 500\n",
      "Created a chunk of size 1946, which is longer than the specified 500\n",
      "Created a chunk of size 719, which is longer than the specified 500\n",
      "Created a chunk of size 2232, which is longer than the specified 500\n",
      "Created a chunk of size 1068, which is longer than the specified 500\n",
      "Created a chunk of size 1238, which is longer than the specified 500\n",
      "Created a chunk of size 573, which is longer than the specified 500\n",
      "Created a chunk of size 676, which is longer than the specified 500\n",
      "Created a chunk of size 1647, which is longer than the specified 500\n",
      "Created a chunk of size 998, which is longer than the specified 500\n",
      "Created a chunk of size 547, which is longer than the specified 500\n",
      "Created a chunk of size 631, which is longer than the specified 500\n",
      "Created a chunk of size 559, which is longer than the specified 500\n",
      "Created a chunk of size 2484, which is longer than the specified 500\n",
      "Created a chunk of size 692, which is longer than the specified 500\n",
      "Created a chunk of size 1166, which is longer than the specified 500\n",
      "Created a chunk of size 582, which is longer than the specified 500\n",
      "Created a chunk of size 1098, which is longer than the specified 500\n",
      "Created a chunk of size 1622, which is longer than the specified 500\n",
      "Created a chunk of size 768, which is longer than the specified 500\n",
      "Created a chunk of size 1545, which is longer than the specified 500\n",
      "Created a chunk of size 1326, which is longer than the specified 500\n",
      "Created a chunk of size 652, which is longer than the specified 500\n",
      "Created a chunk of size 866, which is longer than the specified 500\n",
      "Created a chunk of size 1391, which is longer than the specified 500\n",
      "Created a chunk of size 1551, which is longer than the specified 500\n",
      "Created a chunk of size 1017, which is longer than the specified 500\n",
      "Created a chunk of size 761, which is longer than the specified 500\n",
      "Created a chunk of size 1181, which is longer than the specified 500\n",
      "Created a chunk of size 545, which is longer than the specified 500\n",
      "Created a chunk of size 907, which is longer than the specified 500\n",
      "Created a chunk of size 776, which is longer than the specified 500\n",
      "Created a chunk of size 660, which is longer than the specified 500\n",
      "Created a chunk of size 632, which is longer than the specified 500\n",
      "Created a chunk of size 628, which is longer than the specified 500\n",
      "Created a chunk of size 539, which is longer than the specified 500\n",
      "Created a chunk of size 607, which is longer than the specified 500\n",
      "Created a chunk of size 517, which is longer than the specified 500\n",
      "Created a chunk of size 955, which is longer than the specified 500\n",
      "Created a chunk of size 706, which is longer than the specified 500\n",
      "Created a chunk of size 567, which is longer than the specified 500\n",
      "Created a chunk of size 942, which is longer than the specified 500\n",
      "Created a chunk of size 998, which is longer than the specified 500\n",
      "Created a chunk of size 1214, which is longer than the specified 500\n",
      "Created a chunk of size 1807, which is longer than the specified 500\n",
      "Created a chunk of size 931, which is longer than the specified 500\n",
      "Created a chunk of size 962, which is longer than the specified 500\n",
      "Created a chunk of size 605, which is longer than the specified 500\n",
      "Created a chunk of size 744, which is longer than the specified 500\n",
      "Created a chunk of size 886, which is longer than the specified 500\n",
      "Created a chunk of size 3761, which is longer than the specified 500\n",
      "Created a chunk of size 1258, which is longer than the specified 500\n",
      "Created a chunk of size 863, which is longer than the specified 500\n",
      "Created a chunk of size 963, which is longer than the specified 500\n",
      "Created a chunk of size 807, which is longer than the specified 500\n",
      "Created a chunk of size 1484, which is longer than the specified 500\n",
      "Created a chunk of size 954, which is longer than the specified 500\n",
      "Created a chunk of size 1367, which is longer than the specified 500\n",
      "Created a chunk of size 840, which is longer than the specified 500\n",
      "Created a chunk of size 1026, which is longer than the specified 500\n",
      "Created a chunk of size 982, which is longer than the specified 500\n",
      "Created a chunk of size 1249, which is longer than the specified 500\n",
      "Created a chunk of size 1391, which is longer than the specified 500\n",
      "Created a chunk of size 1535, which is longer than the specified 500\n",
      "Created a chunk of size 1361, which is longer than the specified 500\n",
      "Created a chunk of size 969, which is longer than the specified 500\n",
      "Created a chunk of size 1184, which is longer than the specified 500\n",
      "Created a chunk of size 2158, which is longer than the specified 500\n",
      "Created a chunk of size 919, which is longer than the specified 500\n",
      "Created a chunk of size 1525, which is longer than the specified 500\n",
      "Created a chunk of size 1112, which is longer than the specified 500\n",
      "Created a chunk of size 1163, which is longer than the specified 500\n",
      "Created a chunk of size 984, which is longer than the specified 500\n",
      "Created a chunk of size 971, which is longer than the specified 500\n",
      "Created a chunk of size 3510, which is longer than the specified 500\n",
      "Created a chunk of size 904, which is longer than the specified 500\n",
      "Created a chunk of size 1464, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "# Dividir el texto (chunks de 500)\n",
    "splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.create_documents([clean_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfdb9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_2648\\1506595998.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "# Crear los embeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03d3cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo FLAN-T5 optimizado para QA\n",
    "model_id = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7be5ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Crear pipeline de Hugging Face\n",
    "hf_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "139c00fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_2648\\307879458.py:2: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=hf_pipeline)\n"
     ]
    }
   ],
   "source": [
    "# Crear LLM para LangChain usando el pipeline\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6284a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la cadena RAG\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=db.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284cc276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta generada: He is ill\n",
      "\n",
      "Documentos fuente utilizados:\n",
      "DR. JEKYLL WAS QUITE AT EASE\n",
      "‚ÄúI have had a shock,‚Äù he said, ‚Äúand I shall never recover. It is a\n",
      "question of weeks. Well, life has been pleasant; I liked it; yes, sir,\n",
      "I used to like it. I sometimes think if we knew all, we should be more\n",
      "glad to get away.‚Äù\n",
      "\n",
      "‚ÄúJekyll is ill, too,‚Äù observed Utterson. ‚ÄúHave you seen him?‚Äù\n",
      "‚ÄúYou know I never approved of it,‚Äù pursued Utterson, ruthlessly\n",
      "disregarding the fresh topic.\n",
      "\n",
      "‚ÄúMy will? Yes, certainly, I know that,‚Äù said the doctor, a trifle\n",
      "sharply. ‚ÄúYou have told me so.‚Äù\n",
      "\n",
      "‚ÄúWell, I tell you so again,‚Äù continued the lawyer. ‚ÄúI have been\n",
      "learning something of young Hyde.‚Äù\n",
      "\n",
      "The large handsome face of Dr. Jekyll grew pale to the very lips, and\n",
      "there came a blackness about his eyes. ‚ÄúI do not care to hear more,‚Äù\n",
      "said he. ‚ÄúThis is a matter I thought we had agreed to drop.‚Äù\n",
      "‚ÄúSo you found it out, did you?‚Äù said Utterson. ‚ÄúBut if that be so, we\n",
      "may step into the court and take a look at the windows. To tell you the\n",
      "truth, I am uneasy about poor Jekyll; and even outside, I feel as if\n",
      "the presence of a friend might do him good.‚Äù\n"
     ]
    }
   ],
   "source": [
    "# Realizar una consulta al sistema RAG\n",
    "query = \"What happens to Dr. Jekyll?\"\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "\n",
    "print(\"Respuesta generada:\", result[\"result\"])\n",
    "\n",
    "print(\"\\nDocumentos fuente utilizados:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(doc.page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1010efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preguntas\n",
    "questions = [\n",
    "    \"Who is the main character of the book?\",\n",
    "    \"What is the book about?\",\n",
    "    \"What is the main theme?\",\n",
    "    \"What happens to Dr. Jekyll?\",\n",
    "    \"Who is Mr. Hyde?\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde8a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (797 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta 1: Who is the main character of the book?\n",
      "Respuesta:\n",
      "Edward Hyde\n",
      "Pregunta 2: What is the book about?\n",
      "Respuesta:\n",
      "a lawyer\n",
      "Pregunta 3: What is the main theme?\n",
      "Respuesta:\n",
      "The doctor's case\n",
      "Pregunta 4: What happens to Dr. Jekyll?\n",
      "Respuesta:\n",
      "He is ill\n",
      "Pregunta 5: Who is Mr. Hyde?\n",
      "Respuesta:\n",
      "a person of small stature\n"
     ]
    }
   ],
   "source": [
    "# Respuestas\n",
    "for i, question in enumerate(questions):\n",
    "    print(f\"Pregunta {i+1}: {question}\")\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    print(\"Respuesta:\")\n",
    "    print(result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
